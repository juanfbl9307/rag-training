{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:24.396568Z",
     "start_time": "2025-02-02T23:13:23.190534Z"
    }
   },
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:25.121881Z",
     "start_time": "2025-02-02T23:13:24.401106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"montuno\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ],
   "id": "8739e72268b30014",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add Documents",
   "id": "808868141880d089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:26.938389Z",
     "start_time": "2025-02-02T23:13:25.251792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/real-state/proyectos.md\")  # Reemplaza con la ruta de tu archivo\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,  # Tamaño de cada chunk (en caracteres)\n",
    "    chunk_overlap=20,  # Superposición entre chunks\n",
    "    length_function=len,  # Función para calcular la longitud del texto\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 4. Almacenar los embeddings en una base de datos vectorial (FAISS en este caso)\n",
    "vector_db = vector_store.from_documents(chunks, embeddings)\n"
   ],
   "id": "3afafc68e9382fa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query From vector store",
   "id": "be58f4998e766db8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:27.614250Z",
     "start_time": "2025-02-02T23:13:26.946538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"cash\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"news\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ],
   "id": "a1c7b2f576511088",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:28.328195Z",
     "start_time": "2025-02-02T23:13:27.624754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = vector_store.similarity_search_with_score(\"how many cash stolen?\",k=2)\n",
    "print(docs)"
   ],
   "id": "a7b05936c363cfc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retriever",
   "id": "2cec90dcffb0d6eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:13:28.341441Z",
     "start_time": "2025-02-02T23:13:28.338475Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vector_store.as_retriever()",
   "id": "9b52887bf686a9dc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt template",
   "id": "190cd1724da664ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG Chain",
   "id": "cb3d72f6b243a9a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:16:45.117195Z",
     "start_time": "2025-02-02T23:16:45.091325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5, model=model, max_tokens=4096)\n",
    "template = \"\"\"Responde las siguientes preguntas con base en los siguientes contexto:\n",
    "Eres un asistente virtual especializado en una agencia inmobiliaria. Tu tarea es proporcionar información precisa y útil sobre los proyectos inmobiliarios disponibles. Utiliza únicamente la información proporcionada en los documentos para responder, el año actual es 2025.\n",
    "\n",
    "Proyectos disponibles:\n",
    "1. **Proyecto A**: Residencial \"Bosque Verde\"\n",
    "2. **Proyecto B**: Comercial \"Plaza Sol\"\n",
    "3. **Proyecto C**: Residencial de lujo \"Altos del Mar\"\n",
    "\n",
    "Instrucciones:\n",
    "- Responde de manera clara y concisa.\n",
    "- Si no tienes información suficiente, indica que no cuentas con los detalles necesarios.\n",
    "- Prioriza la información sobre ubicación, precios, características y disponibilidad.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "9aedd97d5dbfcada",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:16:49.313943Z",
     "start_time": "2025-02-02T23:16:47.316068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = rag_chain.invoke(\"cuando entregan el proyecto A?\")\n",
    "print(response)"
   ],
   "id": "ad66716817840325",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El proyecto A, \"Residencial Bosque Verde\", se entregará en el segundo semestre del año 2026.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG Graph",
   "id": "cc46dfd7d38e8335"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:18:49.924589Z",
     "start_time": "2025-02-02T23:18:49.758348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_template.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "8605b2ca2d27948f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:20:15.870123Z",
     "start_time": "2025-02-02T23:20:13.504038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = graph.invoke({\"question\": \"cual es el proyecto mas barato y mas costoso? dame la diferencia de precios\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "c256a67f028064c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El proyecto más barato es el **Proyecto A: Residencial \"Bosque Verde\"** y el más costoso es el **Proyecto C: Residencial de lujo \"Altos del Mar\"**. La diferencia de precios entre ambos proyectos es de $300,000.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
