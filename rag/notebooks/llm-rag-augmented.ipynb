{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:58.515155Z",
     "start_time": "2025-02-12T13:59:58.417706Z"
    }
   },
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import chromadb\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5, model=model, max_tokens=4096)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "from langchain_chroma import Chroma\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"data-chunking-pdf\"\n",
    "\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "print(chroma_client.heartbeat())\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"llm-rag-ai\",\n",
    "    embedding_function=embeddings,\n",
    "    client=chroma_client\n",
    ")\n",
    "retriever = vector_store.as_retriever()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739368798506000275\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:22.992336Z",
     "start_time": "2025-02-12T13:59:22.989339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "template = \"\"\"\n",
    "**Context**: {context}\n",
    "You are an AI assistant specialized in answering questions about Artificial Intelligence (AI), Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Python programming. Your task is to provide clear, accurate, and concise explanations. If the question is outside your scope, politely inform the user.\n",
    "\n",
    "**User Question**: {question}\n",
    "\n",
    "**Your Response**:\n",
    "1. Provide a clear and structured answer.\n",
    "2. Include examples, code snippets, or analogies if applicable.\n",
    "3. Do not include any additional explanations or context.\n",
    "4. Do not hallucinate.\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ],
   "id": "1e4fcf5ba340e3b2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:23.027172Z",
     "start_time": "2025-02-12T13:59:23.025007Z"
    }
   },
   "cell_type": "code",
   "source": "question = \"provide me a good example of rag applied to real-state\"",
   "id": "9a205dd5ede93f7f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:23.044678Z",
     "start_time": "2025-02-12T13:59:23.042018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "#\n",
    "# rag_chain = (\n",
    "#         {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#         | prompt_template\n",
    "#         | llm\n",
    "#         | StrOutputParser()\n",
    "# )\n",
    "#\n",
    "# response = rag_chain.invoke(question)\n",
    "# print(response)"
   ],
   "id": "87071815fe0b7f25",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:23.059878Z",
     "start_time": "2025-02-12T13:59:23.053769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"],k=3)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_template.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "af6ed2a1aebf98db",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T13:59:25.937991Z",
     "start_time": "2025-02-12T13:59:23.068219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = graph.invoke({\"question\": question})\n",
    "print(response[\"answer\"])"
   ],
   "id": "a3bd2512d0288d81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good example of Retrieval-Augmented Generation (RAG) applied to real estate is in generating property valuations and recommendations. Here's how it works:\n",
      "\n",
      "1. **Data Collection**: The RAG model collects and retrieves data from various sources such as historical housing prices, local market trends, demographic information, and economic indicators.\n",
      "\n",
      "2. **Analysis and Generation**: The model analyzes this data using machine learning algorithms to understand patterns and trends. It then generates accurate property valuations and recommendations.\n",
      "\n",
      "3. **Personalized Recommendations**: Real estate agents can input specific property details or client preferences into the RAG model, which will generate tailored recommendations and valuations. This helps agents make informed decisions and provide better service to clients.\n",
      "\n",
      "This application enhances the decision-making process in real estate by providing data-driven insights and reducing the reliance on subjective judgment.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
